{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import struct\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from six.moves import cPickle\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 20 #latent dimension\n",
    "n_hidden = 500 # hidden units\n",
    "lr = 0.001 # learning rate\n",
    "beta_reg = 1.0 # for beta-VAE, 1.0 corresponds to usual VAE\n",
    "gamma = 0.0 # warping parameter\n",
    "N = 60000 # number of train samples in MNIST\n",
    "N_test = 10000 # number of test samples in MNIST\n",
    "batch_size = 50\n",
    "max_epochs = 1 # number of epochs used for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE IMPLEMENTATION\n",
    "tf.reset_default_graph()\n",
    "\n",
    "eps = tf.placeholder(tf.float32, shape=(None, d))  # variables to reparametrize to sample from approx posterior\n",
    "z_gen = tf.placeholder(tf.float32, shape=(None, d))  # used only for generative samples (samples from prior)\n",
    "X = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "# the following two placeholders should be obtained by running the graph and generating samples from the model\n",
    "# they are used to compute the inception score\n",
    "class_distr_gen = tf.placeholder(tf.float32, shape=(10))  # this is intended to be the generative label distribution\n",
    "X_gen = tf.placeholder(tf.float32, shape=(None, 784))  # these are generated samples\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "with tf.variable_scope('ELBO', reuse=tf.AUTO_REUSE):\n",
    "    mu_Z, sigma_Z = encoder_mnist(X, n_hidden, d, keep_prob)\n",
    "Z = mu_Z + sigma_Z * eps  # [batch_size, d]\n",
    "\n",
    "with tf.variable_scope('ELBO', reuse=tf.AUTO_REUSE):\n",
    "    alpha_X, beta_X = decoder_mnist_beta(Z, n_hidden, 784, keep_prob)\n",
    "    # sample from the model\n",
    "    alpha_X_gen, beta_X_gen = decoder_mnist_beta(z_gen, n_hidden, 784, keep_prob)\n",
    "\n",
    "clipped_X = tf.clip_by_value(X, 1e-4, 1 - 1e-4)\n",
    "log_norm_const = tf.lgamma(alpha_X + beta_X) - tf.lgamma(alpha_X) - tf.lgamma(beta_X)\n",
    "log_p_all = tf.reduce_sum((alpha_X - 1.0) * tf.log(clipped_X) + (beta_X - 1.0) * tf.log(1.0 - clipped_X)\n",
    "                          + log_norm_const, 1)\n",
    "log_p = tf.reduce_mean(log_p_all)\n",
    "# computing an IW estimate of the log likelihood requires having k epsilon samples per data point in the batch,\n",
    "# so that eps would have to be shaped [None, d, k], which would complicate the rest of the graph.\n",
    "# since trainin with IWAE is not required here, only the log importance weights are computed in the graph and the\n",
    "# log likelihood estimate is computed outside the graph by calling it several times for the same batch but with\n",
    "# different random epsilons.\n",
    "log_iw = log_p_all + tf.reduce_sum(-0.5 * tf.square(Z), 1)\n",
    "log_iw = log_iw + tf.reduce_sum(tf.log(1e-8 + sigma_Z) + tf.square(mu_Z - Z) / (2.0 * tf.square(sigma_Z)), 1)\n",
    "\n",
    "KL = 0.5 * tf.reduce_sum(tf.square(mu_Z) + tf.square(sigma_Z) - tf.log(1e-8 + tf.square(sigma_Z)) - 1.0, 1)\n",
    "KL = tf.reduce_mean(KL)\n",
    "\n",
    "ELBO = log_p - beta_reg * KL\n",
    "cost = - ELBO\n",
    "\n",
    "log_p_all_cheat = tf.reduce_sum((alpha_X - 1.0) * tf.log(clipped_X) + (beta_X - 1.0) * tf.log(1.0 - clipped_X), 1)\n",
    "log_p_cheat = tf.reduce_mean(log_p_all_cheat)\n",
    "ELBO_cheat = log_p_cheat - beta_reg * KL\n",
    "cost_cheat = - ELBO_cheat\n",
    "log_iw_cheat = log_iw - log_p_all + log_p_all_cheat\n",
    "\n",
    "with tf.variable_scope('classifier', reuse=tf.AUTO_REUSE):\n",
    "    class_logits = classifier_mnist(X, n_hidden, 10, keep_prob)\n",
    "    class_logits_gen = classifier_mnist(X_gen, n_hidden, 10, keep_prob)\n",
    "acc = 1.0 - tf.reduce_mean(tf.abs(tf.sign(tf.cast(tf.argmax(class_logits, 1) - tf.argmax(labels, 1), tf.float32))))\n",
    "class_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=class_logits, labels=labels))\n",
    "class_probs_gen = tf.clip_by_value(tf.nn.softmax(class_logits_gen), 1e-4, 1 - 1e-4)\n",
    "is_kl = tf.reduce_sum(class_probs_gen * (tf.log(class_probs_gen) - tf.log(class_distr_gen)), axis=1)\n",
    "log_is = tf.reduce_mean(is_kl)\n",
    "\n",
    "optim = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "all_params_ELBO = tf.trainable_variables(scope='ELBO')\n",
    "grads_and_vars = optim.compute_gradients(cost, all_params_ELBO)\n",
    "clipped_grads_and_vars = [(tf.clip_by_value(grad, -1.0, 1.0), var) for grad, var in grads_and_vars]\n",
    "optimizer = optim.apply_gradients(clipped_grads_and_vars)\n",
    "\n",
    "optim_cheat = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "grads_and_vars_cheat = optim_cheat.compute_gradients(cost_cheat, all_params_ELBO)\n",
    "clipped_grads_and_vars_cheat = [(tf.clip_by_value(grad, -1.0, 1.0), var) for grad, var in grads_and_vars_cheat]\n",
    "optimizer_cheat = optim_cheat.apply_gradients(clipped_grads_and_vars_cheat)\n",
    "\n",
    "optim_class = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "all_params_class = tf.trainable_variables(scope='classifier')\n",
    "grads_and_vars_class = optim.compute_gradients(class_loss, all_params_class)\n",
    "clipped_grads_and_vars_class = [(tf.clip_by_value(grad, -1.0, 1.0), var) for grad, var in grads_and_vars_class]\n",
    "optimizer_class = optim_class.apply_gradients(clipped_grads_and_vars_class)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS TO EVALUATE METRICS ONCE THE MODEL IS TRAINED\n",
    "\n",
    "def epoch_metrics(N, d, batch_size, X_eval, k=100):\n",
    "    assert np.shape(X_eval)[0] % batch_size == 0\n",
    "    ELBO_val = 0.0\n",
    "    ELBO_cheat_val = 0.0\n",
    "    IW_ELBO = 0.0\n",
    "    IW_cheat = 0.0\n",
    "    local_perms = PermManager(np.shape(X_eval)[0], batch_size)\n",
    "    while local_perms.epoch < 1:\n",
    "        eps_batch = np.random.normal(size=[batch_size, d])\n",
    "        batch = local_perms.get_indices()\n",
    "        X_batch = np.reshape(X_eval[batch, :], [batch_size, -1])\n",
    "        ELBO_val_batch, ELBO_cheat_val_batch = sess.run([ELBO, ELBO_cheat], {eps: eps_batch, X: X_batch, keep_prob: 1.0})\n",
    "        ELBO_val += ELBO_val_batch\n",
    "        ELBO_cheat_val += ELBO_cheat_val_batch\n",
    "        increase_IW_ELBO = []\n",
    "        increase_IW_cheat = []\n",
    "        for i in xrange(k):\n",
    "            eps_batch = np.random.normal(size=[batch_size, d])\n",
    "            inc_IW_ELBO, inc_IW_cheat = sess.run([log_iw, log_iw_cheat], {eps: eps_batch, X: X_batch, keep_prob: 1.0})\n",
    "            increase_IW_ELBO.append(inc_IW_ELBO)\n",
    "            increase_IW_cheat.append(inc_IW_cheat)\n",
    "        increase_IW_ELBO = np.array(increase_IW_ELBO)\n",
    "        a_ELBO = np.max(increase_IW_ELBO, axis=0)\n",
    "        IW_ELBO += np.mean(a_ELBO + np.log(np.sum(np.exp(increase_IW_ELBO - a_ELBO), 0)) - np.log(k))\n",
    "        increase_IW_cheat = np.array(increase_IW_cheat)\n",
    "        a_cheat = np.max(increase_IW_cheat, axis=0)\n",
    "        IW_cheat += np.mean(a_cheat + np.log(np.sum(np.exp(increase_IW_cheat - a_cheat), 0)) - np.log(k))\n",
    "    ELBO_val = ELBO_val * batch_size / N\n",
    "    ELBO_cheat_val = ELBO_cheat_val * batch_size / N\n",
    "    IW_ELBO = IW_ELBO * batch_size / N\n",
    "    IW_cheat = IW_cheat * batch_size / N\n",
    "    del local_perms\n",
    "    return ELBO_val, ELBO_cheat_val, IW_ELBO, IW_cheat\n",
    "\n",
    "\n",
    "def compute_IS(batch_size, samples):\n",
    "    # computes the inception score using samples\n",
    "    N_samples = np.shape(samples)[0]\n",
    "    class_distr_val = np.zeros(10)\n",
    "    local_perms = PermManager(N_samples, batch_size)\n",
    "    while local_perms.epoch < 1:\n",
    "        batch = local_perms.get_indices()\n",
    "        samples_batch = np.reshape(samples[batch], [batch_size, -1])\n",
    "        class_distr_val += np.sum(sess.run(class_probs_gen, {X_gen: samples_batch, keep_prob: 1.0}), axis=0)\n",
    "    class_distr_val = class_distr_val / N_samples\n",
    "    log_is_val = 0.0\n",
    "    local_perms = PermManager(N_samples, batch_size)\n",
    "    while local_perms.epoch < 1:\n",
    "        batch = local_perms.get_indices()\n",
    "        samples_batch = np.reshape(samples[batch], [batch_size, -1])\n",
    "        log_is_val += sess.run(log_is, {X_gen: samples_batch, class_distr_gen: class_distr_val, keep_prob:1.0})\n",
    "    log_is_val = log_is_val * batch_size / N\n",
    "    is_val = np.exp(log_is_val)\n",
    "    return is_val\n",
    "\n",
    "\n",
    "def sample_from_model_beta(batch_size, N):\n",
    "    # gives back N samples from the model\n",
    "    assert N % batch_size == 0\n",
    "    K = N / batch_size\n",
    "    samples_alpha = []\n",
    "    samples_beta = []\n",
    "    for i in xrange(K):\n",
    "        alpha_batch, beta_batch = sess.run([alpha_X_gen, beta_X_gen], {z_gen: np.random.normal(size=[batch_size, d]), keep_prob: 1.0})\n",
    "        samples_alpha.append(alpha_batch)\n",
    "        samples_beta.append(beta_batch)\n",
    "    return np.concatenate(samples_alpha), np.concatenate(samples_beta)\n",
    "\n",
    "\n",
    "def k_nn_acc(k, batch_size, X_eval, digits_eval, X_train, digits_train):\n",
    "    # computes the knn metric from the model's latent variables\n",
    "    assert np.shape(X_eval)[0] % batch_size == 0\n",
    "    assert np.shape(X_eval)[0] == np.shape(digits_eval)[0]\n",
    "    assert np.shape(X_train)[0] % batch_size == 0\n",
    "    assert np.shape(X_train)[0] == np.shape(digits_train)[0]\n",
    "    local_perms = PermManager(np.shape(X_train)[0], batch_size, perm=np.arange(np.shape(X_train)[0]))\n",
    "    mu_vals_train = []\n",
    "    while local_perms.epoch < 1:\n",
    "        batch = local_perms.get_indices()\n",
    "        X_batch = np.reshape(X_train[batch, :], [batch_size, -1])\n",
    "        mu_vals_train.append(sess.run(mu_Z, {X: X_batch, keep_prob: 1.0}))\n",
    "    mu_vals_train = np.concatenate(mu_vals_train)\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(mu_vals_train, digits_train)\n",
    "    local_perms = PermManager(np.shape(X_eval)[0], batch_size, perm=np.arange(np.shape(X_eval)[0]))\n",
    "    mu_vals_eval = []\n",
    "    while local_perms.epoch < 1:\n",
    "        batch = local_perms.get_indices()\n",
    "        X_batch = np.reshape(X_eval[batch, :], [batch_size, -1])\n",
    "        mu_vals_eval.append(sess.run(mu_Z, {X: X_batch, keep_prob: 1.0}))\n",
    "    mu_vals_eval = np.concatenate(mu_vals_eval)\n",
    "    digit_pred = classifier.predict(mu_vals_eval)\n",
    "    del local_perms\n",
    "    return float(np.sum(digit_pred == digits_eval)) / np.shape(X_eval)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AND WARP MNIST\n",
    "train_img, train_digits = read_mnist(path='./mnist/')\n",
    "test_img, test_digits = read_mnist(dataset='testing', path='./mnist/')\n",
    "train_img = (np.array(train_img, dtype='float32') + np.array(np.random.random((60000, 28, 28)),\n",
    "                                                             dtype='float32')) / 256.0\n",
    "train_img = warp(train_img, gamma)\n",
    "test_img = (np.array(test_img, dtype='float32') + np.array(np.random.random((10000, 28, 28)),\n",
    "                                                           dtype='float32')) / 256.0\n",
    "test_img = warp(test_img, gamma)\n",
    "train_lbl = make_one_hot(train_digits, 10)\n",
    "test_lbl = make_one_hot(test_digits, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN CLASSIFIER (USED TO COMPUTE INCEPTION SCORES)\n",
    "\n",
    "sess.run(init_op)\n",
    "\n",
    "perms = PermManager(N, batch_size)\n",
    "while True:\n",
    "    start_epoch = perms.epoch\n",
    "    batch = perms.get_indices()\n",
    "    X_batch = np.reshape(train_img[batch, :], [batch_size, -1])\n",
    "    labels_batch = train_lbl[batch]\n",
    "    _, c = sess.run([optimizer_class, class_loss], {X: X_batch, labels: labels_batch, keep_prob: 0.9})\n",
    "    if perms.epoch >= max_epochs:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN BETA DISTRIBUTION VAE\n",
    "\n",
    "sess.run(init_op)  # uncomment to restart variables\n",
    "\n",
    "perms = PermManager(N, batch_size)\n",
    "while True:\n",
    "    start_epoch = perms.epoch\n",
    "    eps_batch = np.random.normal(size=[batch_size, d])\n",
    "    batch = perms.get_indices()\n",
    "    X_batch = np.reshape(train_img[batch, :], [batch_size, -1])\n",
    "    _, c = sess.run([optimizer, cost], {eps: eps_batch, X: X_batch, keep_prob: 0.9})\n",
    "    if perms.epoch >= max_epochs:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch metrics computes ELBOs and log likelihoods, both including and ignoring normalizing constants\n",
    "print epoch_metrics(N_test, d, batch_size, test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the knn metric to measure usefulness of latents\n",
    "print k_nn_acc(15, batch_size, test_img, test_digits, train_img, train_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SHOW MODEL SAMPLES\n",
    "\n",
    "ind = 0\n",
    "samples = sample_from_model_beta(100, 100)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(np.reshape(samples[0][ind] / (samples[1][ind] + samples[1][ind]), [28, 28]), norm=None, vmin=0.0, vmax=1.0,\n",
    "           cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    plt.subplot(241 + i)\n",
    "    plt.imshow(np.reshape(samples[0][i] / (samples[1][i] + samples[1][i]), [28, 28]), \n",
    "               norm=None, vmin=0.0, vmax=1.0, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE INCEPTION SCORES\n",
    "\n",
    "samples = sample_from_model_beta(batch_size, N)\n",
    "# uncomment to select which IS to compute\n",
    "# new_samples = np.reshape(train_img, [N, 784]) # data\n",
    "new_samples = sample_beta(samples[0], samples[1]) # beta from decoder output\n",
    "# new_samples = mean_from_params_beta(samples[0], samples[1]) # decoder output (mean)\n",
    "\n",
    "print compute_IS(batch_size, new_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAIN BETA DISTRIBUTION VAE WHILE IGNORING THE NORMALIZING CONSTANT\n",
    "\n",
    "sess.run(init_op)  # uncomment to restart variables, should be done if regular beta distr VAE was previously trained\n",
    "\n",
    "perms = PermManager(N, batch_size)\n",
    "while True:\n",
    "    start_epoch = perms.epoch\n",
    "    eps_batch = np.random.normal(size=[batch_size, d])\n",
    "    batch = perms.get_indices()\n",
    "    X_batch = np.reshape(train_img[batch, :], [batch_size, -1])\n",
    "    _, c = sess.run([optimizer_cheat, cost_cheat], {eps: eps_batch, X: X_batch, keep_prob: 0.9})\n",
    "    if perms.epoch >= max_epochs:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print epoch_metrics(N_test, d, batch_size, test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print k_nn_acc(15, batch_size, test_img, test_digits, train_img, train_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "samples = sample_from_model_beta(100, 100)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(np.reshape(samples[0][ind] / (samples[1][ind] + samples[1][ind]), [28, 28]), norm=None, vmin=0.0, vmax=1.0,\n",
    "           cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THAT CLASSIFIER SHOULD BE RETRAINED BEFORE RUNNING THIS IF THE BETA DISTR VAE THAT IGNORES THE NORMALIZING\n",
    "# CONSTANT WAS THE LAST TRAINED ONE\n",
    "\n",
    "samples = sample_from_model_beta(batch_size, N)\n",
    "# uncomment to select which IS to compute\n",
    "# new_samples = np.reshape(train_img, [N, 784]) # data\n",
    "# new_samples = sample_beta(samples[0], samples[1]) # norm from decoder output\n",
    "new_samples = mean_from_params_beta(samples[0], samples[1]) # decoder output (mean)\n",
    "\n",
    "print compute_IS(batch_size, new_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
